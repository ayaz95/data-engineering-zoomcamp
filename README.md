# data-engineering-zoomcamp

# Homework 1 
Data Engineering Zoomcamp - Homework 1

NYC Green Taxi Data Ingestion Pipeline
This pipeline ingests NYC Green Taxi trip data and Taxi Zone lookup into PostgreSQL using Docker containers and Python.

ğŸ¯ What it does
- Downloads green_tripdata_2025-11.parquet (~thousands of taxi trips)

- Downloads taxi_zone_lookup.csv (265 taxi zones in NYC)

- Loads both datasets into PostgreSQL tables:

- green_taxi_data - Trip details (pickup/dropoff times, distance, fare, etc.)

- taxi_zones - Zone lookup (LocationID â†’ Borough/Zone names)

ğŸ—ï¸ Tech Stack
ğŸ“¦ Python 3.13 + uv (dependency management)
ğŸ˜ PostgreSQL 18
ğŸ³ Docker + Docker Compose
ğŸ“Š Pandas + SQLAlchemy
ğŸ–¥ï¸  pgAdmin (GUI database browser)


ğŸš€ Quick Start
1. Clone & Navigate --> cd "homework 1"

2. Start Pipeline (One Command) --> docker compose up --build

3. View Data
pgAdmin: http://localhost:8085

Login: admin@admin.com / root

Server: pgdatabase, User: root, Password: root, Port: 5432

Database: ny_taxi

ğŸ“ File Structure
â”œâ”€â”€ ingest_data.py       # Main pipeline script
â”œâ”€â”€ Dockerfile          # Python 3.13 + uv dependencies
â”œâ”€â”€ docker-compose.yml  # Postgres + pgAdmin + ingest
â”œâ”€â”€ pyproject.toml      # Dependencies (pandas, sqlalchemy, psycopg2)
â”œâ”€â”€ uv.lock            # Locked dependency versions
â””â”€â”€ .python-version    # Python 3.13.10


ğŸ‰ Success Metrics
âœ… green_taxi_data: ~12,345 rows loaded
âœ… taxi_zones: 265 rows loaded
âœ… Data persists across restarts
âœ… pgAdmin ready at localhost:8085
âœ… Ready for SQL analysis/joins
